{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qdOVt66CdUL9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-lGYixYIdUMB",
        "outputId": "cac6e232-823c-4623-def2-42eb2cac4426",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-b470ffd4532e>:2: DtypeWarning: Columns (35,36,37,38,39) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv(\"engineered_transactions.csv\")\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "data = pd.read_csv(\"engineered_transactions.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lEv_1-OodUMC",
        "outputId": "548c07ed-3f51-491f-e9da-1317b82da401",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Distribution:\n",
            "is_bad\n",
            "0    0.615906\n",
            "1    0.384094\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Create RFM-based target variable\n",
        "rfm_thresholds = {\n",
        "    'Recency': data[\"Recency\"].quantile(0.8),\n",
        "    'Frequency': data[\"Frequency\"].quantile(0.2),\n",
        "    'Monetary': data[\"Monetary\"].quantile(0.2)\n",
        "}\n",
        "\n",
        "data[\"is_bad\"] = np.where(\n",
        "    (data[\"Recency\"] > rfm_thresholds['Recency']) |\n",
        "    (data[\"Frequency\"] < rfm_thresholds['Frequency']) |\n",
        "    (data[\"Monetary\"] < rfm_thresholds['Monetary']),\n",
        "    1, 0\n",
        ")\n",
        "\n",
        "print(\"Target Distribution:\")\n",
        "print(data[\"is_bad\"].value_counts(normalize=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dgJ23dM3dUMD"
      },
      "outputs": [],
      "source": [
        "# Feature engineering\n",
        "def feature_engineering(df):\n",
        "    # Extract temporal features\n",
        "    if 'TransactionStartTime' in df.columns:\n",
        "        df['TransactionStartTime'] = pd.to_datetime(df['TransactionStartTime'])\n",
        "        df['TransactionHour'] = df['TransactionStartTime'].dt.hour\n",
        "        df['TransactionDay'] = df['TransactionStartTime'].dt.day\n",
        "        df['TransactionMonth'] = df['TransactionStartTime'].dt.month\n",
        "        df = df.drop('TransactionStartTime', axis=1)\n",
        "    return df\n",
        "\n",
        "data = feature_engineering(data)\n",
        "\n",
        "# Drop non-predictive columns\n",
        "data = data.drop([\n",
        "    \"TransactionId\", \"BatchId\", \"AccountId\",\n",
        "    \"SubscriptionId\", \"CustomerId\"\n",
        "], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gT578DuNdUMD"
      },
      "outputs": [],
      "source": [
        "# Split data\n",
        "X = data.drop(\"is_bad\", axis=1)\n",
        "y = data[\"is_bad\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7PB8t3AedUME"
      },
      "outputs": [],
      "source": [
        "# Preprocessing pipeline\n",
        "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = X.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "N12C5VTwdUME"
      },
      "outputs": [],
      "source": [
        "# Model pipelines\n",
        "log_reg = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(class_weight='balanced', max_iter=1000))\n",
        "])\n",
        "\n",
        "rf = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(class_weight='balanced'))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "10J_dl4ddUMF"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter tuning\n",
        "param_grid_lr = {\n",
        "    'classifier__C': [0.01, 0.1, 1, 10],\n",
        "    'classifier__solver': ['lbfgs', 'saga']\n",
        "}\n",
        "\n",
        "param_grid_rf = {\n",
        "    'classifier__n_estimators': [100, 200],\n",
        "    'classifier__max_depth': [None, 10, 20],\n",
        "    'classifier__min_samples_split': [2, 5]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WAUeGhJzdUMF",
        "outputId": "3f90e265-30c5-4810-def0-2c92cf11a853",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "\nAll the 24 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n24 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_encode.py\", line 183, in _unique_python\n    uniques = sorted(uniques_set)\n              ^^^^^^^^^^^^^^^^^^^\nTypeError: '<' not supported between instances of 'str' and 'bool'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 654, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 588, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\", line 1001, in fit_transform\n    result = self._call_func_on_transformers(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\", line 910, in _call_func_on_transformers\n    return Parallel(n_jobs=self.n_jobs)(jobs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 77, in __call__\n    return super().__call__(iterable_with_config)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1918, in __call__\n    return output if self.return_generator else list(output)\n                                                ^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n    res = func(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 139, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 730, in fit_transform\n    return last_step.fit_transform(\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 921, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_encoders.py\", line 991, in fit\n    self._fit(\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_encoders.py\", line 103, in _fit\n    result = _unique(Xi, return_counts=compute_counts)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_encode.py\", line 52, in _unique\n    return _unique_python(\n           ^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_encode.py\", line 188, in _unique_python\n    raise TypeError(\nTypeError: Encoders require their input argument must be uniformly strings or numbers. Got ['bool', 'str']\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-2100586b41ac>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mlr_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Logistic Regression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mrf_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid_rf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Random Forest\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-2100586b41ac>\u001b[0m in \u001b[0;36mtrain_evaluate\u001b[0;34m(model, param_grid, model_name)\u001b[0m\n\u001b[1;32m      3\u001b[0m     grid_search = GridSearchCV(model, param_grid, cv=3, \n\u001b[1;32m      4\u001b[0m                               scoring='roc_auc', n_jobs=-1)\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1571\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    999\u001b[0m                     )\n\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m                 \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m                 \u001b[0;31m# For callable self.scoring, the return type is only know after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    515\u001b[0m                 \u001b[0;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             )\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: \nAll the 24 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n24 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_encode.py\", line 183, in _unique_python\n    uniques = sorted(uniques_set)\n              ^^^^^^^^^^^^^^^^^^^\nTypeError: '<' not supported between instances of 'str' and 'bool'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 654, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 588, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\", line 1001, in fit_transform\n    result = self._call_func_on_transformers(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\", line 910, in _call_func_on_transformers\n    return Parallel(n_jobs=self.n_jobs)(jobs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 77, in __call__\n    return super().__call__(iterable_with_config)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1918, in __call__\n    return output if self.return_generator else list(output)\n                                                ^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n    res = func(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 139, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 730, in fit_transform\n    return last_step.fit_transform(\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 921, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_encoders.py\", line 991, in fit\n    self._fit(\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_encoders.py\", line 103, in _fit\n    result = _unique(Xi, return_counts=compute_counts)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_encode.py\", line 52, in _unique\n    return _unique_python(\n           ^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_encode.py\", line 188, in _unique_python\n    raise TypeError(\nTypeError: Encoders require their input argument must be uniformly strings or numbers. Got ['bool', 'str']\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate models\n",
        "def train_evaluate(model, param_grid, model_name):\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=3,\n",
        "                              scoring='roc_auc', n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    best_model = grid_search.best_estimator_\n",
        "    y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    print(f\"\\n{model_name} Best Parameters:\", grid_search.best_params_)\n",
        "    print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, best_model.predict(X_test)))\n",
        "\n",
        "    return best_model\n",
        "\n",
        "lr_best = train_evaluate(log_reg, param_grid_lr, \"Logistic Regression\")\n",
        "rf_best = train_evaluate(rf, param_grid_rf, \"Random Forest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLd7FgL3dUMG",
        "outputId": "f06cc1e3-bdc3-4db9-fd7a-31f165ed6d44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target Distribution:\n",
            "is_bad\n",
            "0    0.626937\n",
            "1    0.373063\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Save best model and preprocessing pipeline\n",
        "joblib.dump(lr_best, 'credit_scoring_lr.pkl')\n",
        "joblib.dump(rf_best, 'credit_scoring_rf.pkl')\n",
        "print(\"\\nModels saved successfully!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVKdoQiPdUMG"
      },
      "outputs": [],
      "source": [
        "# Feature importance analysis (for Random Forest)\n",
        "try:\n",
        "    feature_names = numeric_features.tolist() + \\\n",
        "        lr_best.named_steps['preprocessor']\\\n",
        "        .named_transformers_['cat']\\\n",
        "        .named_steps['onehot']\\\n",
        "        .get_feature_names_out(categorical_features).tolist()\n",
        "\n",
        "    importances = rf_best.named_steps['classifier'].feature_importances_\n",
        "    feat_imp = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
        "    print(\"\\nTop 10 Important Features:\")\n",
        "    print(feat_imp.sort_values(by='importance', ascending=False).head(10))\n",
        "except Exception as e:\n",
        "    print(\"\\nFeature importance analysis skipped:\", str(e))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}