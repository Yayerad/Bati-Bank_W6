{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qdOVt66CdUL9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lGYixYIdUMB",
        "outputId": "cac6e232-823c-4623-def2-42eb2cac4426"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-5-b470ffd4532e>:2: DtypeWarning: Columns (35,36,37,38,39) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv(\"engineered_transactions.csv\")\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "data = pd.read_csv(\"engineered_transactions.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEv_1-OodUMC",
        "outputId": "548c07ed-3f51-491f-e9da-1317b82da401"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target Distribution:\n",
            "is_bad\n",
            "0    0.615906\n",
            "1    0.384094\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Create RFM-based target variable\n",
        "rfm_thresholds = {\n",
        "    'Recency': data[\"Recency\"].quantile(0.8),\n",
        "    'Frequency': data[\"Frequency\"].quantile(0.2),\n",
        "    'Monetary': data[\"Monetary\"].quantile(0.2)\n",
        "}\n",
        "\n",
        "data[\"is_bad\"] = np.where(\n",
        "    (data[\"Recency\"] > rfm_thresholds['Recency']) |\n",
        "    (data[\"Frequency\"] < rfm_thresholds['Frequency']) |\n",
        "    (data[\"Monetary\"] < rfm_thresholds['Monetary']),\n",
        "    1, 0\n",
        ")\n",
        "\n",
        "print(\"Target Distribution:\")\n",
        "print(data[\"is_bad\"].value_counts(normalize=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dgJ23dM3dUMD"
      },
      "outputs": [],
      "source": [
        "# Feature engineering\n",
        "def feature_engineering(df):\n",
        "    # Extract temporal features\n",
        "    if 'TransactionStartTime' in df.columns:\n",
        "        df['TransactionStartTime'] = pd.to_datetime(df['TransactionStartTime'])\n",
        "        df['TransactionHour'] = df['TransactionStartTime'].dt.hour\n",
        "        df['TransactionDay'] = df['TransactionStartTime'].dt.day\n",
        "        df['TransactionMonth'] = df['TransactionStartTime'].dt.month\n",
        "        df = df.drop('TransactionStartTime', axis=1)\n",
        "    return df\n",
        "\n",
        "data = feature_engineering(data)\n",
        "\n",
        "# Drop non-predictive columns\n",
        "data = data.drop([\n",
        "    \"TransactionId\", \"BatchId\", \"AccountId\",\n",
        "    \"SubscriptionId\", \"CustomerId\"\n",
        "], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gT578DuNdUMD"
      },
      "outputs": [],
      "source": [
        "# Split data\n",
        "X = data.drop(\"is_bad\", axis=1)\n",
        "y = data[\"is_bad\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7PB8t3AedUME"
      },
      "outputs": [],
      "source": [
        "# Preprocessing pipeline\n",
        "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = X.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "N12C5VTwdUME"
      },
      "outputs": [],
      "source": [
        "# Model pipelines\n",
        "log_reg = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(class_weight='balanced', max_iter=1000))\n",
        "])\n",
        "\n",
        "rf = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(class_weight='balanced'))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "10J_dl4ddUMF"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter tuning\n",
        "param_grid_lr = {\n",
        "    'classifier__C': [0.01, 0.1, 1, 10],\n",
        "    'classifier__solver': ['lbfgs', 'saga']\n",
        "}\n",
        "\n",
        "param_grid_rf = {\n",
        "    'classifier__n_estimators': [100, 200],\n",
        "    'classifier__max_depth': [None, 10, 20],\n",
        "    'classifier__min_samples_split': [2, 5]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ZAeE532ziJOX"
      },
      "outputs": [],
      "source": [
        "# Convert categorical features to string\n",
        "X_train[categorical_features] = X_train[categorical_features].astype(str)\n",
        "X_test[categorical_features] = X_test[categorical_features].astype(str)\n",
        "\n",
        "# Fill NaN values in categorical columns\n",
        "X_train[categorical_features] = X_train[categorical_features].fillna(\"Unknown\")\n",
        "X_test[categorical_features] = X_test[categorical_features].fillna(\"Unknown\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAUeGhJzdUMF",
        "outputId": "d98c6206-82d2-4bf9-8486-fcdbedb71a8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Logistic Regression Best Parameters: {'classifier__C': 10, 'classifier__solver': 'lbfgs'}\n",
            "ROC-AUC Score: 0.9862\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.94      0.94      3434\n",
            "           1       0.90      0.89      0.90      2142\n",
            "\n",
            "    accuracy                           0.92      5576\n",
            "   macro avg       0.92      0.92      0.92      5576\n",
            "weighted avg       0.92      0.92      0.92      5576\n",
            "\n",
            "\n",
            "Random Forest Best Parameters: {'classifier__max_depth': 20, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 100}\n",
            "ROC-AUC Score: 1.0000\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      3434\n",
            "           1       1.00      1.00      1.00      2142\n",
            "\n",
            "    accuracy                           1.00      5576\n",
            "   macro avg       1.00      1.00      1.00      5576\n",
            "weighted avg       1.00      1.00      1.00      5576\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate models\n",
        "def train_evaluate(model, param_grid, model_name):\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=3,\n",
        "                              scoring='roc_auc', n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    best_model = grid_search.best_estimator_\n",
        "    y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    print(f\"\\n{model_name} Best Parameters:\", grid_search.best_params_)\n",
        "    print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, best_model.predict(X_test)))\n",
        "\n",
        "    return best_model\n",
        "\n",
        "lr_best = train_evaluate(log_reg, param_grid_lr, \"Logistic Regression\")\n",
        "rf_best = train_evaluate(rf, param_grid_rf, \"Random Forest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLd7FgL3dUMG",
        "outputId": "c57596d7-5a98-41fd-ebc4-f107db5cebce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Models saved successfully!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Save best model and preprocessing pipeline\n",
        "joblib.dump(lr_best, 'credit_scoring_lr.pkl')\n",
        "joblib.dump(rf_best, 'credit_scoring_rf.pkl')\n",
        "print(\"\\nModels saved successfully!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVKdoQiPdUMG",
        "outputId": "c9ca930c-5416-466c-e232-4a706850bb5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 10 Important Features:\n",
            "                     feature  importance\n",
            "5                    Recency    0.312954\n",
            "12          TransactionCount    0.164556\n",
            "6                  Frequency    0.143768\n",
            "7                   Monetary    0.112825\n",
            "10    TotalTransactionAmount    0.109422\n",
            "11  AverageTransactionAmount    0.057920\n",
            "8                  Stability    0.032727\n",
            "2                      Value    0.020269\n",
            "1                     Amount    0.016944\n",
            "3            PricingStrategy    0.014801\n"
          ]
        }
      ],
      "source": [
        "# Feature importance analysis (for Random Forest)\n",
        "try:\n",
        "    feature_names = numeric_features.tolist() + \\\n",
        "        lr_best.named_steps['preprocessor']\\\n",
        "        .named_transformers_['cat']\\\n",
        "        .named_steps['onehot']\\\n",
        "        .get_feature_names_out(categorical_features).tolist()\n",
        "\n",
        "    importances = rf_best.named_steps['classifier'].feature_importances_\n",
        "    feat_imp = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
        "    print(\"\\nTop 10 Important Features:\")\n",
        "    print(feat_imp.sort_values(by='importance', ascending=False).head(10))\n",
        "except Exception as e:\n",
        "    print(\"\\nFeature importance analysis skipped:\", str(e))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
